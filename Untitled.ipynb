{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1deeb3bb-4b3f-45c9-b13c-41e640afdaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# Common transforms for images\n",
    "transform = T.Compose([\n",
    "    T.Resize((256, 256), interpolation=InterpolationMode.NEAREST),\n",
    "    T.ToTensor(),\n",
    "    # Optionally, normalize here\n",
    "    # T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "    #             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Common transforms for masks\n",
    "transform_mask = T.Compose([\n",
    "    T.Resize((256, 256), interpolation=InterpolationMode.NEAREST),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea72872-a487-41c2-8c99-312707b48951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyLabeledDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, transform_mask=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.transform_mask = transform_mask\n",
    "        \n",
    "        self.images = sorted([\n",
    "            os.path.join(image_dir, x) \n",
    "            for x in os.listdir(image_dir) \n",
    "            if x.endswith('.png') or x.endswith('.jpg')\n",
    "        ])\n",
    "        \n",
    "        self.masks = sorted([\n",
    "            os.path.join(mask_dir, x) \n",
    "            for x in os.listdir(mask_dir) \n",
    "            if x.endswith('.png') or x.endswith('.jpg')\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # or \"L\" if grayscale\n",
    "\n",
    "        # Load corresponding mask\n",
    "        mask_path = self.masks[idx]\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # single-channel\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "\n",
    "        # Binarize the mask (assuming foreground is > 0.5)\n",
    "        mask = (mask > 0.5).long()  \n",
    "        mask = mask.squeeze(0)     \n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class MyUnlabeledDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted([\n",
    "            os.path.join(image_dir, x) \n",
    "            for x in os.listdir(image_dir) \n",
    "            if x.endswith('.png') or x.endswith('.jpg')\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d0cca0-4860-42ad-9203-8314a3562f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=2):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(64+64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(32+32, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.seg_head = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        b = self.bottleneck(p2)\n",
    "\n",
    "        u2 = self.up2(b)\n",
    "        cat2 = torch.cat([u2, e2], dim=1)\n",
    "        d2 = self.dec2(cat2)\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        cat1 = torch.cat([u1, e1], dim=1)\n",
    "        d1 = self.dec1(cat1)\n",
    "\n",
    "        return self.seg_head(d1)  # shape: [N, out_channels, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95cf9f8e-3dcc-49e3-a3b9-1a407407e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UltraSemiNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=2, alpha=0.99):\n",
    "        super(UltraSemiNet, self).__init__()\n",
    "        # Student and Teacher share the same architecture\n",
    "        self.student_net = SimpleUNet(in_channels, num_classes)\n",
    "        self.teacher_net = SimpleUNet(in_channels, num_classes)\n",
    "        \n",
    "        # Initialize teacher weights to match student initially\n",
    "        self._update_teacher(0.0)\n",
    "        # Exponential moving average factor for teacher update\n",
    "        self.alpha = alpha\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.student_net(x)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _update_teacher(self, alpha=None):\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "        for teacher_param, student_param in zip(self.teacher_net.parameters(), \n",
    "                                                self.student_net.parameters()):\n",
    "            teacher_param.data = alpha * teacher_param.data + (1 - alpha) * student_param.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4c8eef-1ea9-4865-8566-5b7bbae98f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sat_loss(anchor, pos, neg, temperature=0.07):\n",
    "    # Dot products for anchor-positive and anchor-negative\n",
    "    sim_pos = (anchor * pos).sum(dim=1) / temperature\n",
    "    sim_neg = (anchor * neg).sum(dim=1) / temperature\n",
    "    \n",
    "    # SAT Loss is based on softmax cross-entropy\n",
    "    logits = torch.stack([sim_pos, sim_neg], dim=1)\n",
    "    labels = torch.zeros(anchor.size(0), dtype=torch.long, device=anchor.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def compute_hardness_map(logits):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    ent = -torch.sum(probs * torch.log(probs + 1e-8), dim=1, keepdim=True)\n",
    "    return ent\n",
    "\n",
    "def aldc_loss(features, labels, mask, temperature=0.07):\n",
    "    B, C, H, W = features.shape\n",
    "    features_2d = features.permute(0,2,3,1).reshape(-1, C) \n",
    "    labels_2d = labels.reshape(-1)     \n",
    "    mask_2d = mask.reshape(-1) > 0.5\n",
    "\n",
    "    idxs = torch.where(mask_2d)[0]\n",
    "    if len(idxs) < 2:\n",
    "        return torch.tensor(0.0, device=features.device)  # no \"hard\" region\n",
    "\n",
    "    # Pick random anchor in the masked region\n",
    "    anchor_idx = idxs[torch.randint(0, len(idxs), (1,))]\n",
    "    anchor_feat = features_2d[anchor_idx]  # shape (C,)\n",
    "    anchor_label = labels_2d[anchor_idx]\n",
    "    same_label_idx = idxs[(labels_2d[idxs] == anchor_label)]\n",
    "    if len(same_label_idx) < 2:\n",
    "        return torch.tensor(0.0, device=features.device)\n",
    "    pos_idx = same_label_idx[torch.randint(0, len(same_label_idx), (1,))]\n",
    "    pos_feat = features_2d[pos_idx]\n",
    "    diff_label_idx = idxs[(labels_2d[idxs] != anchor_label)]\n",
    "    if len(diff_label_idx) < 1:\n",
    "        return torch.tensor(0.0, device=features.device)\n",
    "    neg_idx = diff_label_idx[torch.randint(0, len(diff_label_idx), (1,))]\n",
    "    neg_feat = features_2d[neg_idx]\n",
    "\n",
    "    # Same form as sat_loss\n",
    "    sim_pos = (anchor_feat * pos_feat).sum() / temperature\n",
    "    sim_neg = (anchor_feat * neg_feat).sum() / temperature\n",
    "    logits = torch.stack([sim_pos, sim_neg], dim=0).unsqueeze(0)\n",
    "    labels_val = torch.zeros(1, dtype=torch.long, device=features.device)\n",
    "\n",
    "    return F.cross_entropy(logits, labels_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b4f5f8-cb7c-40e7-a350-8afde7b1c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_ultraseminet(\n",
    "    student_teacher_model,\n",
    "    dataloader_labeled,\n",
    "    dataloader_unlabeled,\n",
    "    optimizer,\n",
    "    num_epochs=10,\n",
    "    temperature=0.07,\n",
    "    lambda_sat=0.5,\n",
    "    lambda_aldc=0.5,\n",
    "    save_path=\"model.pth\"\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_teacher_model = student_teacher_model.to(device)\n",
    "    criterion_ce = nn.CrossEntropyLoss()\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        student_teacher_model.train()\n",
    "        running_loss = 0.0\n",
    "        steps = 0\n",
    "        steps_per_epoch = min(len(dataloader_labeled), len(dataloader_unlabeled))\n",
    "\n",
    "        # Create the tqdm progress bar\n",
    "        pbar = tqdm(\n",
    "            zip(dataloader_labeled, dataloader_unlabeled),\n",
    "            total=steps_per_epoch,\n",
    "            desc=f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "        )\n",
    "        for (x_l, y_l), x_u in pbar:\n",
    "            x_l, y_l = x_l.to(device), y_l.to(device)\n",
    "            x_u = x_u.to(device)\n",
    "\n",
    "            # Supervised loss\n",
    "            logits_l = student_teacher_model(x_l)\n",
    "            sup_loss = criterion_ce(logits_l, y_l)\n",
    "\n",
    "            # Pseudo-label generation (teacher side)\n",
    "            with torch.no_grad():\n",
    "                logits_u_teacher = student_teacher_model.teacher_net(x_u)\n",
    "                pseudo_labels = torch.argmax(logits_u_teacher, dim=1)\n",
    "            \n",
    "            # Student forward on unlabeled data\n",
    "            logits_u_student = student_teacher_model(x_u)\n",
    "            unsup_loss_ce = criterion_ce(logits_u_student, pseudo_labels)\n",
    "\n",
    "            # Features for SAT loss\n",
    "            features_student_u = F.adaptive_avg_pool2d(logits_u_student, (1,1)).squeeze(-1).squeeze(-1)\n",
    "            features_teacher_u = F.adaptive_avg_pool2d(logits_u_teacher, (1,1)).squeeze(-1).squeeze(-1)\n",
    "\n",
    "            # Negative examples by shuffling\n",
    "            batch_size = features_student_u.size(0)\n",
    "            indices = torch.randperm(batch_size, device=device)\n",
    "            neg_features = features_student_u[indices]\n",
    "\n",
    "            # SAT loss\n",
    "            sat_loss_val = sat_loss(features_student_u, features_teacher_u, neg_features, temperature)\n",
    "\n",
    "            # ALDC loss on labeled data (using hardness map from teacher)\n",
    "            with torch.no_grad():\n",
    "                logits_l_hard = student_teacher_model.teacher_net(x_l)\n",
    "            hardness_map = compute_hardness_map(logits_l_hard)\n",
    "            mask = (hardness_map > 0.5).float()\n",
    "\n",
    "            aldc_val = aldc_loss(logits_l, y_l.unsqueeze(1), mask, temperature)\n",
    "\n",
    "            # Total loss\n",
    "            total_loss = sup_loss + unsup_loss_ce + lambda_sat*sat_loss_val + lambda_aldc*aldc_val\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # EMA update for teacher\n",
    "            student_teacher_model._update_teacher()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "            steps += 1\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.set_postfix({\n",
    "                \"SupLoss\": f\"{sup_loss.item():.4f}\",\n",
    "                \"UnsupLoss\": f\"{unsup_loss_ce.item():.4f}\",\n",
    "                \"SAT\": f\"{sat_loss_val.item():.4f}\",\n",
    "                \"ALDC\": f\"{aldc_val.item():.4f}\",\n",
    "                \"Total\": f\"{total_loss.item():.4f}\"\n",
    "            })\n",
    "\n",
    "        epoch_loss = running_loss / steps if steps > 0 else 0.0\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(student_teacher_model.state_dict(), save_path)\n",
    "            print(f\"Model saved at epoch {epoch+1} with loss={epoch_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a7877-e630-4ff5-bf87-d758287c1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "# from ultra_semi_net import UltraSemiNet\n",
    "# from train import train_ultraseminet\n",
    "# from datasets import MyLabeledDataset, MyUnlabeledDataset\n",
    "# from transformations import transform, transform_mask\n",
    "\n",
    "labeled_image_dir = '/home/ufaqkhan/UltraSemiNet/Dataset/labeled/original'\n",
    "labeled_mask_dir = '/home/ufaqkhan/UltraSemiNet/Dataset/labeled/groundtruth'\n",
    "unlabeled_image_dir = '/home/ufaqkhan/UltraSemiNet/Dataset/unlabeled'\n",
    "labeled_dataset = MyLabeledDataset(\n",
    "    image_dir=labeled_image_dir,\n",
    "    mask_dir=labeled_mask_dir,\n",
    "    transform=transform,\n",
    "    transform_mask=transform_mask\n",
    ")\n",
    "unlabeled_dataset = MyUnlabeledDataset(\n",
    "    image_dir=unlabeled_image_dir,\n",
    "    transform=transform\n",
    ")\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=4, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=4, shuffle=True)\n",
    "model = UltraSemiNet(in_channels=3, num_classes=2, alpha=0.99)  # or in_channels=1 if grayscale\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_ultraseminet(\n",
    "    student_teacher_model=model,\n",
    "    dataloader_labeled=labeled_loader,\n",
    "    dataloader_unlabeled=unlabeled_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    temperature=0.07,\n",
    "    lambda_sat=0.5,\n",
    "    lambda_aldc=0.5,\n",
    "    save_path=\"model.pth\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
