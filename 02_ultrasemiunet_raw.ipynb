{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8ed7e8-80d4-4df5-baf6-b14290a13575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  9.04it/s, SupLoss=1.2245, UnsupLoss=1.0118, SAT=0.6378, ALDC=0.0000, Total=2.5552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] Loss: 2.5828\n",
      "Model saved at epoch 1 with loss=2.5828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 15.69it/s, SupLoss=1.1659, UnsupLoss=1.0160, SAT=0.6303, ALDC=0.0000, Total=2.4970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/10] Loss: 2.5214\n",
      "Model saved at epoch 2 with loss=2.5214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 16.14it/s, SupLoss=1.1104, UnsupLoss=1.0156, SAT=0.6918, ALDC=0.0000, Total=2.4720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/10] Loss: 2.4857\n",
      "Model saved at epoch 3 with loss=2.4857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:01<00:00, 12.90it/s, SupLoss=1.1134, UnsupLoss=1.0172, SAT=0.7012, ALDC=0.0000, Total=2.4812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10] Loss: 2.4830\n",
      "Model saved at epoch 4 with loss=2.4830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:01<00:00, 13.00it/s, SupLoss=1.1092, UnsupLoss=1.0182, SAT=0.6989, ALDC=0.0000, Total=2.4769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] Loss: 2.4815\n",
      "Model saved at epoch 5 with loss=2.4815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 13.03it/s, SupLoss=1.1084, UnsupLoss=1.0190, SAT=0.7056, ALDC=0.0000, Total=2.4802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] Loss: 2.4796\n",
      "Model saved at epoch 6 with loss=2.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 13.07it/s, SupLoss=1.1049, UnsupLoss=1.0212, SAT=0.7304, ALDC=0.0000, Total=2.4913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/10] Loss: 2.4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 13.04it/s, SupLoss=1.1036, UnsupLoss=1.0203, SAT=0.7219, ALDC=0.0000, Total=2.4849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/10] Loss: 2.4813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:01<00:00, 12.94it/s, SupLoss=1.0963, UnsupLoss=1.0207, SAT=0.7269, ALDC=0.0000, Total=2.4804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] Loss: 2.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|█████████████████████████████████████████████████████████████| 13/13 [00:01<00:00, 12.98it/s, SupLoss=1.0906, UnsupLoss=1.0225, SAT=0.7369, ALDC=0.0000, Total=2.4816]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/10] Loss: 2.4773\n",
      "Model saved at epoch 10 with loss=2.4773\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "\n",
    "# Common transforms for images\n",
    "transform = T.Compose([\n",
    "    T.Resize((256, 256), interpolation=InterpolationMode.NEAREST),\n",
    "    T.ToTensor(),\n",
    "    # Optionally, normalize here\n",
    "    # T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "    #             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Common transforms for masks\n",
    "transform_mask = T.Compose([\n",
    "    T.Resize((256, 256), interpolation=InterpolationMode.NEAREST),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "class MyLabeledDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, transform_mask=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.transform_mask = transform_mask\n",
    "        \n",
    "        self.images = sorted([\n",
    "            os.path.join(image_dir, x) \n",
    "            for x in os.listdir(image_dir) \n",
    "            if x.endswith('.png') or x.endswith('.jpg')\n",
    "        ])\n",
    "        \n",
    "        self.masks = sorted([\n",
    "            os.path.join(mask_dir, x) \n",
    "            for x in os.listdir(mask_dir) \n",
    "            if x.endswith('.png') or x.endswith('.jpg')\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # or \"L\" if grayscale\n",
    "\n",
    "        # Load corresponding mask\n",
    "        mask_path = self.masks[idx]\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # single-channel\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "\n",
    "        # Binarize the mask (assuming foreground is > 0.5)\n",
    "        mask = (mask > 0.5).long()  \n",
    "        mask = mask.squeeze(0)     \n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class MyUnlabeledDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted([\n",
    "            os.path.join(image_dir, x) \n",
    "            for x in os.listdir(image_dir) \n",
    "            if x.endswith('.png') or x.endswith('.jpg')\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=2):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(64+64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(32+32, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.seg_head = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        b = self.bottleneck(p2)\n",
    "\n",
    "        u2 = self.up2(b)\n",
    "        cat2 = torch.cat([u2, e2], dim=1)\n",
    "        d2 = self.dec2(cat2)\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        cat1 = torch.cat([u1, e1], dim=1)\n",
    "        d1 = self.dec1(cat1)\n",
    "\n",
    "        return self.seg_head(d1)  # shape: [N, out_channels, H, W]\n",
    "\n",
    "\n",
    "class UltraSemiNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=3, alpha=0.99):\n",
    "        super(UltraSemiNet, self).__init__()\n",
    "        # Student and Teacher share the same architecture\n",
    "        self.student_net = SimpleUNet(in_channels, num_classes)\n",
    "        self.teacher_net = SimpleUNet(in_channels, num_classes)\n",
    "        \n",
    "        # Initialize teacher weights to match student initially\n",
    "        self._update_teacher(0.0)\n",
    "        # Exponential moving average factor for teacher update\n",
    "        self.alpha = alpha\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.student_net(x)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _update_teacher(self, alpha=None):\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "        for teacher_param, student_param in zip(self.teacher_net.parameters(), \n",
    "                                                self.student_net.parameters()):\n",
    "            teacher_param.data = alpha * teacher_param.data + (1 - alpha) * student_param.data\n",
    "\n",
    "\n",
    "def sat_loss(anchor, pos, neg, temperature=0.07):\n",
    "    # Dot products for anchor-positive and anchor-negative\n",
    "    sim_pos = (anchor * pos).sum(dim=1) / temperature\n",
    "    sim_neg = (anchor * neg).sum(dim=1) / temperature\n",
    "    \n",
    "    # SAT Loss is based on softmax cross-entropy\n",
    "    logits = torch.stack([sim_pos, sim_neg], dim=1)\n",
    "    labels = torch.zeros(anchor.size(0), dtype=torch.long, device=anchor.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def compute_hardness_map(logits):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    ent = -torch.sum(probs * torch.log(probs + 1e-8), dim=1, keepdim=True)\n",
    "    return ent\n",
    "\n",
    "def aldc_loss(features, labels, mask, temperature=0.07):\n",
    "    B, C, H, W = features.shape\n",
    "    features_2d = features.permute(0,2,3,1).reshape(-1, C) \n",
    "    labels_2d = labels.reshape(-1)     \n",
    "    mask_2d = mask.reshape(-1) > 0.5\n",
    "\n",
    "    idxs = torch.where(mask_2d)[0]\n",
    "    if len(idxs) < 2:\n",
    "        return torch.tensor(0.0, device=features.device)  # no \"hard\" region\n",
    "\n",
    "    # Pick random anchor in the masked region\n",
    "    anchor_idx = idxs[torch.randint(0, len(idxs), (1,))]\n",
    "    anchor_feat = features_2d[anchor_idx]  # shape (C,)\n",
    "    anchor_label = labels_2d[anchor_idx]\n",
    "    same_label_idx = idxs[(labels_2d[idxs] == anchor_label)]\n",
    "    if len(same_label_idx) < 2:\n",
    "        return torch.tensor(0.0, device=features.device)\n",
    "    pos_idx = same_label_idx[torch.randint(0, len(same_label_idx), (1,))]\n",
    "    pos_feat = features_2d[pos_idx]\n",
    "    diff_label_idx = idxs[(labels_2d[idxs] != anchor_label)]\n",
    "    if len(diff_label_idx) < 1:\n",
    "        return torch.tensor(0.0, device=features.device)\n",
    "    neg_idx = diff_label_idx[torch.randint(0, len(diff_label_idx), (1,))]\n",
    "    neg_feat = features_2d[neg_idx]\n",
    "\n",
    "    # Same form as sat_loss\n",
    "    sim_pos = (anchor_feat * pos_feat).sum() / temperature\n",
    "    sim_neg = (anchor_feat * neg_feat).sum() / temperature\n",
    "    logits = torch.stack([sim_pos, sim_neg], dim=0).unsqueeze(0)\n",
    "    labels_val = torch.zeros(1, dtype=torch.long, device=features.device)\n",
    "\n",
    "    return F.cross_entropy(logits, labels_val)\n",
    "\n",
    "\n",
    "def train_ultraseminet(\n",
    "    student_teacher_model,\n",
    "    dataloader_labeled,\n",
    "    dataloader_unlabeled,\n",
    "    optimizer,\n",
    "    num_epochs=10,\n",
    "    temperature=0.07,\n",
    "    lambda_sat=0.5,\n",
    "    lambda_aldc=0.5,\n",
    "    save_path=\"model.pth\"\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_teacher_model = student_teacher_model.to(device)\n",
    "    criterion_ce = nn.CrossEntropyLoss()\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        student_teacher_model.train()\n",
    "        running_loss = 0.0\n",
    "        steps = 0\n",
    "        steps_per_epoch = min(len(dataloader_labeled), len(dataloader_unlabeled))\n",
    "\n",
    "        # Create the tqdm progress bar\n",
    "        pbar = tqdm(\n",
    "            zip(dataloader_labeled, dataloader_unlabeled),\n",
    "            total=steps_per_epoch,\n",
    "            desc=f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "        )\n",
    "        for (x_l, y_l), x_u in pbar:\n",
    "            x_l, y_l = x_l.to(device), y_l.to(device)\n",
    "            x_u = x_u.to(device)\n",
    "\n",
    "            # Supervised loss\n",
    "            logits_l = student_teacher_model(x_l)\n",
    "            sup_loss = criterion_ce(logits_l, y_l)\n",
    "\n",
    "            # Pseudo-label generation (teacher side)\n",
    "            with torch.no_grad():\n",
    "                logits_u_teacher = student_teacher_model.teacher_net(x_u)\n",
    "                pseudo_labels = torch.argmax(logits_u_teacher, dim=1)\n",
    "            \n",
    "            # Student forward on unlabeled data\n",
    "            logits_u_student = student_teacher_model(x_u)\n",
    "            unsup_loss_ce = criterion_ce(logits_u_student, pseudo_labels)\n",
    "\n",
    "            # Features for SAT loss\n",
    "            features_student_u = F.adaptive_avg_pool2d(logits_u_student, (1,1)).squeeze(-1).squeeze(-1)\n",
    "            features_teacher_u = F.adaptive_avg_pool2d(logits_u_teacher, (1,1)).squeeze(-1).squeeze(-1)\n",
    "\n",
    "            # Negative examples by shuffling\n",
    "            batch_size = features_student_u.size(0)\n",
    "            indices = torch.randperm(batch_size, device=device)\n",
    "            neg_features = features_student_u[indices]\n",
    "\n",
    "            # SAT loss\n",
    "            sat_loss_val = sat_loss(features_student_u, features_teacher_u, neg_features, temperature)\n",
    "\n",
    "            # ALDC loss on labeled data (using hardness map from teacher)\n",
    "            with torch.no_grad():\n",
    "                logits_l_hard = student_teacher_model.teacher_net(x_l)\n",
    "            hardness_map = compute_hardness_map(logits_l_hard)\n",
    "            mask = (hardness_map > 0.5).float()\n",
    "\n",
    "            aldc_val = aldc_loss(logits_l, y_l.unsqueeze(1), mask, temperature)\n",
    "\n",
    "            # Total loss\n",
    "            total_loss = sup_loss + unsup_loss_ce + lambda_sat*sat_loss_val + lambda_aldc*aldc_val\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # EMA update for teacher\n",
    "            student_teacher_model._update_teacher()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "            steps += 1\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.set_postfix({\n",
    "                \"SupLoss\": f\"{sup_loss.item():.4f}\",\n",
    "                \"UnsupLoss\": f\"{unsup_loss_ce.item():.4f}\",\n",
    "                \"SAT\": f\"{sat_loss_val.item():.4f}\",\n",
    "                \"ALDC\": f\"{aldc_val.item():.4f}\",\n",
    "                \"Total\": f\"{total_loss.item():.4f}\"\n",
    "            })\n",
    "\n",
    "        epoch_loss = running_loss / steps if steps > 0 else 0.0\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(student_teacher_model.state_dict(), save_path)\n",
    "            print(f\"Model saved at epoch {epoch+1} with loss={epoch_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "labeled_image_dir = 'dataset/labeled_data/images'\n",
    "labeled_mask_dir = 'dataset/labeled_data/labels'\n",
    "unlabeled_image_dir = 'dataset/unlabeled_data/images'\n",
    "labeled_dataset = MyLabeledDataset(\n",
    "    image_dir=labeled_image_dir,\n",
    "    mask_dir=labeled_mask_dir,\n",
    "    transform=transform,\n",
    "    transform_mask=transform_mask\n",
    ")\n",
    "unlabeled_dataset = MyUnlabeledDataset(\n",
    "    image_dir=unlabeled_image_dir,\n",
    "    transform=transform\n",
    ")\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=4, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=4, shuffle=True)\n",
    "model = UltraSemiNet(in_channels=3, num_classes=3, alpha=0.99)  # or in_channels=1 if grayscale\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_ultraseminet(\n",
    "    student_teacher_model=model,\n",
    "    dataloader_labeled=labeled_loader,\n",
    "    dataloader_unlabeled=unlabeled_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    temperature=0.07,\n",
    "    lambda_sat=0.5,\n",
    "    lambda_aldc=0.5,\n",
    "    save_path=\"model.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e06ced8-5616-4bc5-abac-d73e4146e87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--labeled_img LABELED_IMG]\n",
      "                             [--labeled_mask LABELED_MASK]\n",
      "                             [--unlabeled_img UNLABELED_IMG] [--epochs EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE] [--lr LR]\n",
      "                             [--save_dir SAVE_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-f02115d4-53f7-4de5-994e-a1ef8a0bb2de.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# ----------------------\n",
    "# Enhanced Transforms\n",
    "# ----------------------\n",
    "class RandomCutMix:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > 0.3:  # 30% probability\n",
    "            return img\n",
    "            \n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        batch_size = img.size(0)\n",
    "        index = torch.randperm(batch_size)\n",
    "        \n",
    "        # Create mixed image\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(img.size(), lam)\n",
    "        img[:, :, bbx1:bbx2, bby1:bby2] = img[index, :, bbx1:bbx2, bby1:bby2]\n",
    "        return img\n",
    "\n",
    "    @staticmethod\n",
    "    def rand_bbox(size, lam):\n",
    "        W, H = size[2], size[3]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "        return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "transform_labeled = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(15),\n",
    "    T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_unlabeled = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    T.ColorJitter(0.3, 0.3, 0.3, 0.2),\n",
    "    T.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "    T.ToTensor(),\n",
    "    RandomCutMix(alpha=1.0),\n",
    "    T.RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_mask = T.Compose([\n",
    "    T.Resize((256, 256), interpolation=InterpolationMode.NEAREST),\n",
    "    T.PILToTensor(),\n",
    "    lambda x: x.squeeze(0).long()\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# Dataset Classes\n",
    "# ----------------------\n",
    "class CervicalDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.is_labeled = mask_dir is not None\n",
    "        self.image_paths = sorted([os.path.join(img_dir, f) for f in os.listdir(img_dir) \n",
    "                              if f.endswith(('.png', '.jpg'))])\n",
    "        if self.is_labeled:\n",
    "            self.mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) \n",
    "                                 if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.is_labeled:\n",
    "            mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n",
    "            return transform_labeled(image), transform_mask(mask)\n",
    "        return transform_unlabeled(image)\n",
    "\n",
    "# ----------------------\n",
    "# Enhanced U-Net Model\n",
    "# ----------------------\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        att = self.conv(x)\n",
    "        return x * self.sigmoid(att)\n",
    "\n",
    "class CervicalUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck with attention\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.attention = AttentionBlock(256)\n",
    "        self.feature_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.seg_head = nn.Sequential(\n",
    "            nn.Conv2d(64, num_classes, 1),\n",
    "            nn.BatchNorm2d(num_classes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        bn = self.bottleneck(p2)\n",
    "        att = self.attention(bn)\n",
    "        return self.feature_pool(att).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        bn = self.bottleneck(p2)\n",
    "        bn = self.attention(bn)\n",
    "        \n",
    "        # Decoder\n",
    "        d1 = self.up1(bn)\n",
    "        d1 = torch.cat([d1, e2], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        d2 = self.up2(d1)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        return self.seg_head(d2)\n",
    "\n",
    "# ----------------------\n",
    "# Semi-Supervised Framework\n",
    "# ----------------------\n",
    "class SemiSupervisedModel(nn.Module):\n",
    "    def __init__(self, num_classes=3, alpha=0.999):\n",
    "        super().__init__()\n",
    "        self.student = CervicalUNet(num_classes=num_classes)\n",
    "        self.teacher = CervicalUNet(num_classes=num_classes)\n",
    "        self.alpha = alpha\n",
    "        self._init_teacher()\n",
    "        \n",
    "        # Loss parameters\n",
    "        self.lambda_unsup = 0.1\n",
    "        self.lambda_sat = 0.1\n",
    "        self.conf_thresh = 0.65\n",
    "\n",
    "    def _init_teacher(self):\n",
    "        with torch.no_grad():\n",
    "            for t_param, s_param in zip(self.teacher.parameters(), self.student.parameters()):\n",
    "                t_param.data.copy_(s_param.data)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_teacher(self, global_step):\n",
    "        alpha = min(1 - 1/(global_step/100 + 1), self.alpha)\n",
    "        for t_param, s_param in zip(self.teacher.parameters(), self.student.parameters()):\n",
    "            t_param.data.mul_(alpha).add_(s_param.data, alpha=1-alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "\n",
    "# ----------------------\n",
    "# Loss Functions\n",
    "# ----------------------\n",
    "def compute_sat_loss(student_feats, teacher_feats, temperature=0.1):\n",
    "    student_feats = F.normalize(student_feats, p=2, dim=1)\n",
    "    teacher_feats = F.normalize(teacher_feats, p=2, dim=1)\n",
    "    \n",
    "    sim_matrix = torch.mm(student_feats, teacher_feats.t()) / temperature\n",
    "    pos_sim = torch.diag(sim_matrix)\n",
    "    neg_sim = (sim_matrix.sum(dim=1) - pos_sim) / (sim_matrix.size(1) - 1)\n",
    "    \n",
    "    loss = -torch.log(torch.exp(pos_sim) / (torch.exp(pos_sim) + torch.exp(neg_sim) + 1e-8)).mean()\n",
    "    return loss\n",
    "\n",
    "class AdaptiveLoss(nn.Module):\n",
    "    def __init__(self, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def forward(self, preds, targets):\n",
    "        # Cross-Entropy\n",
    "        ce_loss = F.cross_entropy(preds, targets, weight=self.class_weights)\n",
    "        \n",
    "        # Dice Loss\n",
    "        smooth = 1e-6\n",
    "        preds_soft = F.softmax(preds, dim=1)\n",
    "        targets_oh = F.one_hot(targets, num_classes=preds.shape[1]).permute(0,3,1,2).float()\n",
    "        \n",
    "        intersection = (preds_soft * targets_oh).sum(dim=(2,3))\n",
    "        union = preds_soft.sum(dim=(2,3)) + targets_oh.sum(dim=(2,3))\n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "        \n",
    "        return ce_loss + dice_loss.mean()\n",
    "\n",
    "# ----------------------\n",
    "# Training Utilities\n",
    "# ----------------------\n",
    "def dice_score(pred, target):\n",
    "    smooth = 1e-6\n",
    "    pred = pred.argmax(1)\n",
    "    return (2.0 * (pred * target).sum() + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "\n",
    "def train(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Dataset\n",
    "    labeled_ds = CervicalDataset(args.labeled_img, args.labeled_mask)\n",
    "    unlabeled_ds = CervicalDataset(args.unlabeled_img)\n",
    "    \n",
    "    # Class weights\n",
    "    class_counts = torch.zeros(3)\n",
    "    for _, mask in labeled_ds:\n",
    "        class_counts += torch.bincount(mask.flatten(), minlength=3)\n",
    "    class_weights = 1.0 / (class_counts / class_counts.sum()).to(device)\n",
    "    \n",
    "    # Data loaders\n",
    "    labeled_loader = DataLoader(labeled_ds, batch_size=args.batch_size, shuffle=True, \n",
    "                               num_workers=2, pin_memory=True)\n",
    "    unlabeled_loader = DataLoader(unlabeled_ds, batch_size=args.batch_size*2, shuffle=True,\n",
    "                                 num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # Model\n",
    "    model = SemiSupervisedModel(num_classes=3).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "    \n",
    "    # Losses\n",
    "    sup_criterion = AdaptiveLoss(class_weights)\n",
    "    unsup_criterion = AdaptiveLoss()\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        sup_loss_total = 0.0\n",
    "        unsup_loss_total = 0.0\n",
    "        dice_total = 0.0\n",
    "        \n",
    "        # Dynamic parameters\n",
    "        current_thresh = 0.65 + min(epoch/args.epochs, 1)*0.25  # 0.65 → 0.9\n",
    "        current_lambda_unsup = min(epoch/10 * 0.5, 0.5)\n",
    "        current_lambda_sat = 0.2 * (1 - epoch/args.epochs)\n",
    "        \n",
    "        pbar = tqdm(zip(labeled_loader, unlabeled_loader), \n",
    "                   total=min(len(labeled_loader), len(unlabeled_loader)), \n",
    "                   desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        \n",
    "        for (labeled_x, labeled_y), unlabeled_x in pbar:\n",
    "            labeled_x, labeled_y = labeled_x.to(device), labeled_y.to(device)\n",
    "            unlabeled_x = unlabeled_x.to(device)\n",
    "            \n",
    "            # Supervised Forward\n",
    "            student_preds = model(labeled_x)\n",
    "            sup_loss = sup_criterion(student_preds, labeled_y)\n",
    "            \n",
    "            # Unsupervised Forward\n",
    "            with torch.no_grad():\n",
    "                teacher_preds = model.teacher(unlabeled_x)\n",
    "                pseudo_probs = F.softmax(teacher_preds, dim=1)\n",
    "                max_probs, pseudo_labels = torch.max(pseudo_probs, dim=1)\n",
    "                mask = (max_probs > current_thresh).float()\n",
    "                \n",
    "            unsup_loss = 0.0\n",
    "            if mask.sum() > 0:\n",
    "                student_u_preds = model(unlabeled_x)\n",
    "                unsup_loss = unsup_criterion(student_u_preds, pseudo_labels) * mask.mean()\n",
    "            \n",
    "            # Feature Alignment Loss\n",
    "            with torch.no_grad():\n",
    "                t_features = model.teacher.forward_features(unlabeled_x)\n",
    "            s_features = model.student.forward_features(unlabeled_x)\n",
    "            sat_loss = compute_sat_loss(s_features, t_features)\n",
    "            \n",
    "            # Total Loss\n",
    "            total_loss = sup_loss + current_lambda_unsup*unsup_loss + current_lambda_sat*sat_loss\n",
    "            \n",
    "            # Optimization\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            model.update_teacher(global_step)\n",
    "            global_step += 1\n",
    "            \n",
    "            # Metrics\n",
    "            sup_loss_total += sup_loss.item()\n",
    "            unsup_loss_total += unsup_loss.item() if unsup_loss != 0 else 0\n",
    "            total_loss += total_loss.item()\n",
    "            dice_total += dice_score(student_preds, labeled_y).item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                \"Sup\": f\"{sup_loss.item():.3f}\",\n",
    "                \"Unsup\": f\"{unsup_loss.item():.3f}\" if unsup_loss != 0 else \"0.000\",\n",
    "                \"SAT\": f\"{sat_loss.item():.3f}\",\n",
    "                \"Dice\": f\"{dice_total/(pbar.n+1):.3f}\",\n",
    "                \"Total\": f\"{total_loss.item():.3f}\"\n",
    "            })\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save best model\n",
    "        avg_loss = total_loss / len(labeled_loader)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), f\"{args.save_dir}/best_model.pth\")\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Sup: {sup_loss_total/len(labeled_loader):.3f} \"\n",
    "              f\"Unsup: {unsup_loss_total/len(unlabeled_loader):.3f} \"\n",
    "              f\"Dice: {dice_total/len(labeled_loader):.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--labeled_img\", type=str, default=\"dataset/labeled_data/images\")\n",
    "    parser.add_argument(\"--labeled_mask\", type=str, default=\"dataset/labeled_data/labels\")\n",
    "    parser.add_argument(\"--unlabeled_img\", type=str, default=\"dataset/unlabeled_data/images\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=8)\n",
    "    parser.add_argument(\"--lr\", type=float, default=2e-4)\n",
    "    parser.add_argument(\"--save_dir\", type=str, default=\"checkpoints\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b388e9-1e0c-4c89-9bbb-b7ca0944fc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
